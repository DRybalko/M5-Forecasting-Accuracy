{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_lib import Project\n",
    "project = Project.access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kaggle_submission_file(test):\n",
    "    predictions = test[['id', 'date', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "    \n",
    "    submission = pd.read_csv('/project_data/data_asset/sample_submission.csv')\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/home/wsuser/work/project_data_assets/data_asset/full_data.pkl\")\n",
    "products = pd.read_pickle(\"/home/wsuser/work/project_data_assets/data_asset/products.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(data, products, on = 'id')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_preprocessing import CategoricalEncoder\n",
    "\n",
    "cat_columns = [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
    "encoder = CategoricalEncoder(cat_columns)\n",
    "encoder.encode(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = data.loc[data.part == 'train']\n",
    "test_df = data.loc[data.part == 'test1']\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation split\n",
    "\n",
    "Last 28 days are used for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv('/project_data/data_asset/sales_train_validation.csv')\n",
    "prices = pd.read_csv('/project_data/data_asset/sell_prices.csv')\n",
    "calendar = pd.read_csv('/project_data/data_asset/calendar.csv')\n",
    "\n",
    "train_fold_df = sales_train_validation.iloc[:, :-28]\n",
    "valid_fold_df = sales_train_validation.iloc[:, -28:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_ts(ts):\n",
    "    descr_table = ts.describe()\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"mean\": descr_table[\"mean\"],\n",
    "        \"std\": descr_table[\"std\"],\n",
    "        \"min_value\": descr_table[\"min\"],\n",
    "        \"max_value\": descr_table[\"max\"]\n",
    "        \"median\": ts.median()\n",
    "        \"num_zeros\": (ts == 0).sum()\n",
    "        \"num_nas\": ts.isna().sum()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = train_fold_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.iloc[6:].astype(int).isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1876</th>\n",
       "      <th>d_1877</th>\n",
       "      <th>d_1878</th>\n",
       "      <th>d_1879</th>\n",
       "      <th>d_1880</th>\n",
       "      <th>d_1881</th>\n",
       "      <th>d_1882</th>\n",
       "      <th>d_1883</th>\n",
       "      <th>d_1884</th>\n",
       "      <th>d_1885</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1891 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1876  d_1877  d_1878  d_1879  d_1880  \\\n",
       "0       CA    0    0    0    0  ...       3       1       3       1       2   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       1       0       0       0       0   \n",
       "3       CA    0    0    0    0  ...       4       2       1       4       1   \n",
       "4       CA    0    0    0    0  ...       3       2       2       2       3   \n",
       "\n",
       "   d_1881  d_1882  d_1883  d_1884  d_1885  \n",
       "0       2       0       1       1       1  \n",
       "1       0       1       1       1       1  \n",
       "2       0       0       1       1       0  \n",
       "3       3       5       0       6       6  \n",
       "4       1       0       0       0       0  \n",
       "\n",
       "[5 rows x 1891 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fold_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.loc[(train_df['date'] > '2010-01-01') & (train_df['date'] <= '2016-03-27')]\n",
    "y_train = x_train['demand']\n",
    "x_val = train_df.loc[(train_df['date'] > '2016-03-27') & (train_df['date'] <= '2016-04-24')]\n",
    "y_val = x_val['demand']\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_split(train_dates, train_values, val_dates, val_values):\n",
    "    plt.figure(figsize = (20, 10))\n",
    "    plt.plot(train_dates, train_values)\n",
    "    plt.plot(val_dates, val_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_split(\n",
    "    pd.to_datetime(x_train.loc[x_train.id == \"HOBBIES_1_001_CA_1_validation\", \"date\"]).values,\n",
    "    x_train.loc[x_train.id == \"HOBBIES_1_001_CA_1_validation\", \"demand\"].values,\n",
    "    pd.to_datetime(x_val.loc[x_val.id == \"HOBBIES_1_001_CA_1_validation\", \"date\"]).values,\n",
    "    x_val.loc[x_val.id == \"HOBBIES_1_001_CA_1_validation\", \"demand\"].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['event_type_1', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'shift_t28', \n",
    "             'shift_t29', 'shift_t30', 'rolling_std_t7', 'rolling_std_t30', 'rolling_std_t60',\n",
    "             'rolling_std_t90', 'rolling_std_t180', 'rolling_mean_t7',\n",
    "             'rolling_mean_t30', 'rolling_mean_t60', 'rolling_mean_t90',\n",
    "             'rolling_mean_t180', 'rolling_skew_t30', 'rolling_kurt_t30',\n",
    "             'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t30', 'year', \n",
    "             'quarter', 'month', 'week', 'day', 'dayofweek', 'is_weekend', 'item_id', 'dept_id',\n",
    "             'store_id', 'state_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random hyperparameters\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'rmse',\n",
    "    'objective': 'regression',\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 10, \n",
    "    'colsample_bytree': 0.75}\n",
    "\n",
    "# Initial features\n",
    "#features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'year', 'month', 'wm_yr_wk', 'wday', 'event_name_1',\n",
    "#            'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_t28', 'lag_t29', \n",
    "#            'lag_t30', 'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t30', 'rolling_mean_t90', 'rolling_mean_t180',\n",
    "#            'rolling_std_t30', 'price_change_t1', 'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t30']\n",
    "\n",
    "\n",
    "train_set = lgb.Dataset(x_train[features], y_train)\n",
    "val_set = lgb.Dataset(x_val[features], y_val)\n",
    "\n",
    "model = lgb.train(params, train_set, num_boost_round = 2500, early_stopping_rounds = 1000, valid_sets = [train_set, val_set], verbose_eval = 100)\n",
    "val_pred = model.predict(x_val[features])\n",
    "val_score = np.sqrt(mean_squared_error(val_pred, y_val))\n",
    "print(f'Our val rmse score is {val_score}')\n",
    "\n",
    "del train_set, val_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val[features])\n",
    "x_val['demand'] = y_pred\n",
    "kaggle_submission = create_kaggle_submission_file(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import WRMSSEEvaluator\n",
    "\n",
    "validation_rows = [row for row in kaggle_submission['id'] if 'validation' in row] \n",
    "kaggle_submission = kaggle_submission[kaggle_submission['id'].isin(validation_rows)]\n",
    "valid_preds = kaggle_submission.iloc[:, 1:]\n",
    "valid_preds.columns = valid_fold_df.columns\n",
    "\n",
    "evaluator = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "evaluator.score(valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_indices = np.random.randint(0, valid_fold_df.index.max(), 20)\n",
    "\n",
    "for pred, true in zip(valid_preds.iloc[rand_indices].iterrows(), valid_fold_df.iloc[rand_indices].iterrows()):\n",
    "    plt.figure(figsize = (20, 10))\n",
    "    plt.plot(np.arange(0, true[1].shape[0]), true[1].values)\n",
    "    plt.plot(np.arange(0, true[1].shape[0]), pred[1].values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_df[features])\n",
    "test_df['demand'] = y_pred\n",
    "kaggle_submission = create_kaggle_submission_file(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save_data(\"my_kaggle_submission.csv\", kaggle_submission.to_csv(index = False), overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
