{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tqdm in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (4.45.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_lib import Project\n",
    "project = Project.access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kaggle_submission_file(test):\n",
    "    predictions = test[['id', 'date', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "    \n",
    "    submission = pd.read_csv('/project_data/data_asset/sample_submission.csv')\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/home/wsuser/work/project_data_assets/data_asset/full_data.pkl\")\n",
    "products = pd.read_pickle(\"/home/wsuser/work/project_data_assets/data_asset/products.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(data, products, on = 'id')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_preprocessing import CategoricalEncoder\n",
    "\n",
    "cat_columns = [\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
    "encoder = CategoricalEncoder(cat_columns)\n",
    "encoder.encode(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = data.loc[data.part == 'train']\n",
    "test_df = data.loc[data.part == 'test1']\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation split\n",
    "\n",
    "Last 28 days are used for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv('/project_data/data_asset/sales_train_validation.csv')\n",
    "prices = pd.read_csv('/project_data/data_asset/sell_prices.csv')\n",
    "calendar = pd.read_csv('/project_data/data_asset/calendar.csv')\n",
    "\n",
    "train_fold_df = sales_train_validation.iloc[:, :-28]\n",
    "valid_fold_df = sales_train_validation.iloc[:, -28:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_df.loc[(train_df['date'] > '2013-01-01') & (train_df['date'] <= '2016-03-27')]\n",
    "y_train = x_train['demand']\n",
    "x_val = train_df.loc[(train_df['date'] > '2016-03-27') & (train_df['date'] <= '2016-04-24')]\n",
    "y_val = x_val['demand']\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_split(train_dates, train_values, val_dates, val_values):\n",
    "    plt.figure(figsize = (20, 10))\n",
    "    plt.plot(train_dates, train_values)\n",
    "    plt.plot(val_dates, val_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_val_split(\n",
    "    pd.to_datetime(x_train.loc[x_train.id == \"HOBBIES_1_001_CA_1_validation\", \"date\"]).values,\n",
    "    x_train.loc[x_train.id == \"HOBBIES_1_001_CA_1_validation\", \"demand\"].values,\n",
    "    pd.to_datetime(x_val.loc[x_val.id == \"HOBBIES_1_001_CA_1_validation\", \"date\"]).values,\n",
    "    x_val.loc[x_val.id == \"HOBBIES_1_001_CA_1_validation\", \"demand\"].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive method\n",
    "\n",
    "Calculate mean demand in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = x_train.groupby(\"id\")[\"demand\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_date = pd.merge(x_val, x_train.groupby(\"id\")[\"demand\"].mean(), on = 'id')\n",
    "predictions_by_date = predictions_by_date[[\"id\", \"date\", \"demand_y\"]]\n",
    "predictions_by_date.columns = [\"id\", \"date\", \"demand\"]\n",
    "kaggle_submission = create_kaggle_submission_file(predictions_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rows = [row for row in kaggle_submission['id'] if 'validation' in row] \n",
    "kaggle_submission = kaggle_submission[kaggle_submission['id'].isin(validation_rows)]\n",
    "valid_preds = kaggle_submission.iloc[:, 1:]\n",
    "valid_preds.columns = valid_fold_df.columns\n",
    "\n",
    "evaluator = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "evaluator.score(valid_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels import tsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stats_ARMA_model(df):\n",
    "    prediction = []\n",
    "    for index, row in df.iterrows():\n",
    "        ts = row.T.loc[\"d_1\":\"d_1885\"]\n",
    "        ts.index = pd.date_range(start = \"2011-01-29\", end = \"2016-03-27\")\n",
    "        model = sm.tsa.ARMA(np.asarray(ts), (3,0)).fit(disp=False)\n",
    "        forecast, stderr, conf_int = model.forecast(steps = 28)\n",
    "        prediction.append([row.id] + forecast.tolist())\n",
    "    return pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = apply_stats_ARMA_model(train_fold_df.iloc[:10])\n",
    "submission.columns = kaggle_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = submission.iloc[:, 1:]\n",
    "valid_preds.columns = valid_fold_df.columns\n",
    "\n",
    "evaluator = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "evaluator.score(valid_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stats_exp_smooth_model(df):\n",
    "    prediction = []\n",
    "    for index, row in df.iterrows():\n",
    "        ts = row.T.loc[\"d_1\":\"d_1885\"]\n",
    "        ts.index = pd.date_range(start = \"2011-01-29\", end = \"2016-03-27\")\n",
    "        model = tsa.holtwinters.ExponentialSmoothing(np.asarray(ts)).fit()\n",
    "        forecast = model.forecast(steps = 28)\n",
    "        prediction.append([row.id] + forecast.tolist())\n",
    "    return pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = apply_stats_exp_smooth_model(train_fold_df)\n",
    "submission.columns = kaggle_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = submission.iloc[:, 1:]\n",
    "valid_preds.columns = valid_fold_df.columns\n",
    "\n",
    "evaluator = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "evaluator.score(valid_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['event_type_1', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'shift_t28', \n",
    "             'shift_t29', 'shift_t30', 'rolling_std_t7', 'rolling_std_t30', 'rolling_std_t60',\n",
    "             'rolling_std_t90', 'rolling_std_t180', 'rolling_mean_t7',\n",
    "             'rolling_mean_t30', 'rolling_mean_t60', 'rolling_mean_t90',\n",
    "             'rolling_mean_t180', 'rolling_skew_t30', 'rolling_kurt_t30',\n",
    "             'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t30', 'year', \n",
    "             'quarter', 'month', 'week', 'day', 'dayofweek', 'is_weekend', 'item_id', 'dept_id',\n",
    "             'store_id', 'state_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 2.52089\tvalid_1's rmse: 2.18867\n",
      "[200]\ttraining's rmse: 2.44592\tvalid_1's rmse: 2.16706\n",
      "[300]\ttraining's rmse: 2.40357\tvalid_1's rmse: 2.15259\n"
     ]
    }
   ],
   "source": [
    "# define random hyperparameters\n",
    "\"\"\"\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'rmse',\n",
    "    'objective': 'regression',\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 10, \n",
    "    'colsample_bytree': 0.75}\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "        \"objective\" : \"poisson\",\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "#         \"nthread\" : 4\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 1500,\n",
    "}\n",
    "\n",
    "# Initial features\n",
    "#features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'year', 'month', 'wm_yr_wk', 'wday', 'event_name_1',\n",
    "#            'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_t28', 'lag_t29', \n",
    "#            'lag_t30', 'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t30', 'rolling_mean_t90', 'rolling_mean_t180',\n",
    "#            'rolling_std_t30', 'price_change_t1', 'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t30']\n",
    "\n",
    "\n",
    "train_set = lgb.Dataset(x_train[features], y_train)\n",
    "val_set = lgb.Dataset(x_val[features], y_val)\n",
    "\n",
    "model = lgb.train(params, train_set, valid_sets = [train_set, val_set], verbose_eval = 100)\n",
    "val_pred = model.predict(x_val[features])\n",
    "val_score = np.sqrt(mean_squared_error(val_pred, y_val))\n",
    "print(f'Our val rmse score is {val_score}')\n",
    "\n",
    "del train_set, val_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val[features])\n",
    "x_val['demand'] = y_pred\n",
    "kaggle_submission = create_kaggle_submission_file(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import WRMSSEEvaluator\n",
    "\n",
    "validation_rows = [row for row in kaggle_submission['id'] if 'validation' in row] \n",
    "kaggle_submission = kaggle_submission[kaggle_submission['id'].isin(validation_rows)]\n",
    "valid_preds = kaggle_submission.iloc[:, 1:]\n",
    "valid_preds.columns = valid_fold_df.columns\n",
    "\n",
    "evaluator = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "evaluator.score(valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_indices = np.random.randint(0, valid_fold_df.index.max(), 20)\n",
    "\n",
    "for pred, true in zip(valid_preds.iloc[rand_indices].iterrows(), valid_fold_df.iloc[rand_indices].iterrows()):\n",
    "    plt.figure(figsize = (20, 10))\n",
    "    plt.plot(np.arange(0, true[1].shape[0]), true[1].values)\n",
    "    plt.plot(np.arange(0, true[1].shape[0]), pred[1].values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.fillna(0, inplace = True)\n",
    "x_val.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# initialize Pool\n",
    "train_pool = Pool(x_train[features], \n",
    "                  y_train.astype(int), \n",
    "                  cat_features=['item_id', 'dept_id', 'store_id', 'state_id'])\n",
    "test_pool = Pool(x_val[features], \n",
    "                 cat_features=['item_id', 'dept_id', 'store_id', 'state_id'])\n",
    "\n",
    "del x_train\n",
    "gc.collect()\n",
    "\n",
    "# specify the training parameters \n",
    "model = CatBoostRegressor(iterations=100, \n",
    "                          loss_function='RMSE', \n",
    "                          used_ram_limit=34360000000)\n",
    "#train the model\n",
    "model.fit(train_pool)\n",
    "# make the prediction using the resulting model\n",
    "preds = model.predict(test_pool)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the training parameters \n",
    "model = CatBoostRegressor(iterations=100, \n",
    "                          loss_function='RMSE', \n",
    "                          used_ram_limit=34360000000)\n",
    "#train the model\n",
    "model.fit(train_pool)\n",
    "# make the prediction using the resulting model\n",
    "preds = model.predict(test_pool)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val['demand'] = preds\n",
    "kaggle_submission = create_kaggle_submission_file(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import WRMSSEEvaluator\n",
    "\n",
    "validation_rows = [row for row in kaggle_submission['id'] if 'validation' in row] \n",
    "kaggle_submission = kaggle_submission[kaggle_submission['id'].isin(validation_rows)]\n",
    "valid_preds = kaggle_submission.iloc[:, 1:]\n",
    "valid_preds.columns = valid_fold_df.columns\n",
    "\n",
    "evaluator = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "evaluator.score(valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pool = Pool(test_df[features], \n",
    "                cat_features=['item_id', 'dept_id', 'store_id', 'state_id'])\n",
    "y_pred = model.predict(val_pool)\n",
    "test_df['demand'] = y_pred\n",
    "kaggle_submission = create_kaggle_submission_file(test_df)\n",
    "project.save_data(\"my_kaggle_submission.csv\", kaggle_submission.to_csv(index = False), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_df[features])\n",
    "test_df['demand'] = y_pred\n",
    "kaggle_submission = create_kaggle_submission_file(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save_data(\"my_kaggle_submission.csv\", kaggle_submission.to_csv(index = False), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
