{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from: https://www.kaggle.com/ragnar123/very-fst-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils import reduce_mem_usage\n",
    "from data_preprocessing import CategoricalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_lib import Project\n",
    "project = Project.access()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv('/project_data/data_asset/sales_train_validation.csv')\n",
    "calendar = pd.read_csv('/project_data/data_asset/calendar.csv')\n",
    "sell_prices = pd.read_csv('/project_data/data_asset/sell_prices.csv')\n",
    "submission = pd.read_csv('/project_data/data_asset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = sales_train_validation[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_pickle(\"/home/wsuser/work/project_data_assets/data_asset/products.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = reduce_mem_usage(sales_train_validation)\n",
    "calendar = reduce_mem_usage(calendar)\n",
    "sell_prices = reduce_mem_usage(sell_prices)\n",
    "submission = reduce_mem_usage(submission)\n",
    "products = reduce_mem_usage(products)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data preparation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_sales(df):\n",
    "    return pd.melt(frame = df, \n",
    "                   id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], \n",
    "                   var_name = 'day', \n",
    "                   value_name = 'demand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_calendar(df, calendar):\n",
    "    df_with_cal = pd.merge(df, calendar, how = \"left\", left_on = [\"day\"], right_on = [\"d\"])\n",
    "    df_with_cal.drop(['d', 'day'], inplace = True, axis = 1)\n",
    "    return df_with_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_prices(df, sell_prices):\n",
    "    df_with_prices = df.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "    return df_with_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_feats(df):\n",
    "    df['event_type_1'].fillna('unknown', inplace = True)\n",
    "    df['event_name_1'].fillna('unknown', inplace = True)\n",
    "    df['event_name_2'].fillna('unknown', inplace = True)\n",
    "    df['event_type_2'].fillna('unknown', inplace = True)\n",
    "    df['sell_price'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_PRED = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_demand_features(df):\n",
    "    \n",
    "    # rolling demand features.\n",
    "    for diff in [0, 1, 2]:\n",
    "        shift = DAYS_PRED + diff\n",
    "        df[f\"shift_t{shift}\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "            lambda x: x.shift(shift)\n",
    "        )\n",
    "\n",
    "    for size in [7, 30, 60, 90, 180]:\n",
    "        df[f\"rolling_std_t{size}\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "            lambda x: x.shift(DAYS_PRED).rolling(size).std()\n",
    "        )\n",
    "\n",
    "    for size in [7, 30, 60, 90, 180]:\n",
    "        df[f\"rolling_mean_t{size}\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "            lambda x: x.shift(DAYS_PRED).rolling(size).mean()\n",
    "        )\n",
    "\n",
    "    df[\"rolling_skew_t30\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "        lambda x: x.shift(DAYS_PRED).rolling(30).skew()\n",
    "    )\n",
    "    df[\"rolling_kurt_t30\"] = df.groupby([\"id\"])[\"demand\"].transform(\n",
    "        lambda x: x.shift(DAYS_PRED).rolling(30).kurt()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_price_features(df):\n",
    "    # price features\n",
    "    df[\"shift_price_t1\"] = df.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.shift(1)\n",
    "    )\n",
    "    df[\"price_change_t1\"] = (df[\"shift_price_t1\"] - df[\"sell_price\"]) / (\n",
    "        df[\"shift_price_t1\"]\n",
    "    )\n",
    "    df[\"rolling_price_max_t365\"] = df.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.shift(1).rolling(365).max()\n",
    "    )\n",
    "    df[\"price_change_t365\"] = (df[\"rolling_price_max_t365\"] - df[\"sell_price\"]) / (\n",
    "        df[\"rolling_price_max_t365\"]\n",
    "    )\n",
    "\n",
    "    df[\"rolling_price_std_t7\"] = df.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.rolling(7).std()\n",
    "    )\n",
    "    df[\"rolling_price_std_t30\"] = df.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.rolling(30).std()\n",
    "    )\n",
    "    return df.drop([\"rolling_price_max_t365\", \"shift_price_t1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df, dt_col):\n",
    "    df[dt_col] = pd.to_datetime(df[dt_col])\n",
    "    attrs = [\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        \"month\",\n",
    "        \"week\",\n",
    "        \"day\",\n",
    "        \"dayofweek\",\n",
    "        \"is_year_end\",\n",
    "        \"is_year_start\",\n",
    "        \"is_quarter_end\",\n",
    "        \"is_quarter_start\",\n",
    "        \"is_month_end\",\n",
    "        \"is_month_start\",\n",
    "    ]\n",
    "\n",
    "    for attr in attrs:\n",
    "        dtype = np.int16 if attr == \"year\" else np.int8\n",
    "        df[attr] = getattr(df[dt_col].dt, attr).astype(dtype)\n",
    "\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(np.int8)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event_features(df):\n",
    "    df[\"event_name_1\"] = 1 - df[\"event_name_1\"].isna().astype(int)\n",
    "    df[\"event_name_2\"] = 1 - df[\"event_name_2\"].isna().astype(int)\n",
    "    df.rename(columns={\"event_name_1\": \"is_event_1\", \n",
    "                         \"event_name_2\": \"is_event_2\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split validation and evaluation submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rows = [row for row in submission['id'] if 'validation' in row]\n",
    "evaluation_rows = [row for row in submission['id'] if 'evaluation' in row]\n",
    "submission_validation = submission.loc[submission['id'].isin(validation_rows)]\n",
    "submission_evaluation = submission.loc[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "submission_validation.columns = ['id', 'd_1914', 'd_1915', 'd_1916', 'd_1917', 'd_1918', 'd_1919', 'd_1920', 'd_1921',\n",
    "                                 'd_1922', 'd_1923', 'd_1924', 'd_1925', 'd_1926', 'd_1927', 'd_1928', 'd_1929', 'd_1930', \n",
    "                                 'd_1931', 'd_1932', 'd_1933', 'd_1934', 'd_1935', 'd_1936', 'd_1937', 'd_1938', 'd_1939', \n",
    "                                 'd_1940', 'd_1941']\n",
    "submission_evaluation.columns = ['id', 'd_1942', 'd_1943', 'd_1944', 'd_1945', 'd_1946', 'd_1947', 'd_1948', 'd_1949',\n",
    "                                 'd_1950', 'd_1951', 'd_1952', 'd_1953', 'd_1954', 'd_1955', 'd_1956', 'd_1957', 'd_1958', \n",
    "                                 'd_1959', 'd_1960', 'd_1961', 'd_1962', 'd_1963', 'd_1964', 'd_1965', 'd_1966', 'd_1967', \n",
    "                                 'd_1968', 'd_1969']\n",
    "\n",
    "del submission, validation_rows, evaluation_rows\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_validation = submission_validation.merge(products, how = 'right', on = 'id')\n",
    "submission_evaluation = submission_evaluation.merge(products, how = 'right', on = 'id')\n",
    "del products\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply data preparation pipeline to full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = melt_sales(sales_train_validation)\n",
    "submission_validation = melt_sales(submission_validation)\n",
    "submission_evaluation = melt_sales(submission_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation['part'] = 'train'\n",
    "submission_validation['part'] = 'test1'\n",
    "submission_evaluation['part'] = 'test2'\n",
    "    \n",
    "#data = pd.concat([sales_train_validation, submission_validation], axis = 0)\n",
    "data = pd.concat([sales_train_validation, submission_validation, submission_evaluation], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sales_train_validation, submission_validation, submission_evaluation\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merge_with_calendar(data, calendar)\n",
    "data = merge_with_prices(data, sell_prices)\n",
    "\n",
    "del calendar, sell_prices\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"weekday\", \"wday\", \"month\", \"year\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_demand_features(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_price_features(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_time_features(data, \"date\")\n",
    "gc.collect()\n",
    "data = add_event_features(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_na_feats(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "cat_columns = ['event_type_1', 'event_type_2']\n",
    "encoder = CategoricalEncoder(cat_columns)\n",
    "encoder.encode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"/home/wsuser/work/project_data_assets/data_asset/full_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
