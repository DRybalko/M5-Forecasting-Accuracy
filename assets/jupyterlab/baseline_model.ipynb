{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_lib import Project\n",
    "project = Project.access()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplest baseline model\n",
    "The average of prices for last 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv('/project_data/data_asset/sales_train_validation.csv')\n",
    "sales_train_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('/project_data/data_asset/sample_submission.csv')\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cols = [column for column in sales_train_validation.columns if 'd_' in column] \n",
    "sales_avg_map = sales_train_validation.set_index('id')[d_cols[-30:]].mean(axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcols = [f for f in sample_submission.columns if 'F' in f]\n",
    "for f in fcols:\n",
    "    sample_submission[f] = sample_submission['id'].map(sales_avg_map).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project.save_data(\"my_submission.csv\", sample_submission.to_csv(index=False), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/home/wsuser/work/project_data_assets/data_asset/full_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.loc[data.part == 'train']\n",
    "test_df = data.loc[data.part == 'test1']\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation split\n",
    "\n",
    "Last 28 days are used for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.loc[train_df['date'] <= '2016-03-27']\n",
    "y_train = x_train['demand']\n",
    "x_val = train_df.loc[(train_df['date'] > '2016-03-27') & (train_df['date'] <= '2016-04-24')]\n",
    "y_val = x_val['demand']\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.35535\tvalid_1's rmse: 2.1428\n",
      "[200]\ttraining's rmse: 2.30859\tvalid_1's rmse: 2.13539\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's rmse: 2.3234\tvalid_1's rmse: 2.1331\n",
      "Our val rmse score is 2.133101966070852\n"
     ]
    }
   ],
   "source": [
    "# define random hyperparammeters\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'rmse',\n",
    "    'objective': 'regression',\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'learning_rate': 0.1,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 10, \n",
    "    'colsample_bytree': 0.75}\n",
    "\n",
    "features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'year', 'month', 'wm_yr_wk', 'wday', 'event_name_1',\n",
    "            'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_t28', 'lag_t29', \n",
    "            'lag_t30', 'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t30', 'rolling_mean_t90', 'rolling_mean_t180',\n",
    "            'rolling_std_t30', 'price_change_t1', 'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t30']\n",
    "\n",
    "\n",
    "train_set = lgb.Dataset(x_train[features], y_train)\n",
    "val_set = lgb.Dataset(x_val[features], y_val)\n",
    "\n",
    "model = lgb.train(params, train_set, num_boost_round = 2500, early_stopping_rounds = 50, valid_sets = [train_set, val_set], verbose_eval = 100)\n",
    "val_pred = model.predict(x_val[features])\n",
    "val_score = np.sqrt(mean_squared_error(val_pred, y_val))\n",
    "print(f'Our val rmse score is {val_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kaggle_submission_file(test):\n",
    "    predictions = test[['id', 'date', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "    \n",
    "    submission = pd.read_csv('/project_data/data_asset/sample_submission.csv')\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_df[features])\n",
    "test_df['demand'] = y_pred\n",
    "kaggle_submission = create_kaggle_submission_file(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'my_kaggle_submission.csv',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'asset_id': '84294923-66aa-481b-a5c7-d5792cf3efc3'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save_data(\"my_kaggle_submission.csv\", kaggle_submission.to_csv(index = False), overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
