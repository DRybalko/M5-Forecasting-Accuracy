{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from lightgbm) (1.15.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from lightgbm) (0.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np, pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
    "         \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "        \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n",
    "PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 4, 25, 0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 28 \n",
    "max_lags = 366\n",
    "tr_last = 1913\n",
    "fday = datetime(2016, 4, 25) \n",
    "fday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(is_train = True, nrows = None, first_day = 1200):\n",
    "    \n",
    "    prices = pd.read_csv(\"/project_data/data_asset/sell_prices.csv\", dtype = PRICE_DTYPES)\n",
    "    for col, col_dtype in PRICE_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "            prices[col] -= prices[col].min()\n",
    "            \n",
    "    cal = pd.read_csv(\"/project_data/data_asset/calendar.csv\", dtype = CAL_DTYPES)\n",
    "    cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
    "    for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
    "            cal[col] -= cal[col].min()\n",
    "    \n",
    "    start_day = max(1 if is_train  else tr_last-max_lags, first_day)\n",
    "    numcols = [f\"d_{day}\" for day in range(start_day,tr_last+1)]\n",
    "    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    dtype = {numcol:\"float32\" for numcol in numcols} \n",
    "    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n",
    "    dt = pd.read_csv(\"/project_data/data_asset/sales_train_validation.csv\", \n",
    "                     nrows = nrows, usecols = catcols + numcols, dtype = dtype)\n",
    "    \n",
    "    for col in catcols:\n",
    "        if col != \"id\":\n",
    "            dt[col] = dt[col].cat.codes.astype(\"int16\")\n",
    "            dt[col] -= dt[col].min()\n",
    "    \n",
    "    if not is_train:\n",
    "        for day in range(tr_last+1, tr_last+ 2*h +1):\n",
    "            dt[f\"d_{day}\"] = np.nan\n",
    "    \n",
    "    dt = pd.melt(dt,\n",
    "                  id_vars = catcols,\n",
    "                  value_vars = [col for col in dt.columns if col.startswith(\"d_\")],\n",
    "                  var_name = \"d\",\n",
    "                  value_name = \"sales\")\n",
    "    \n",
    "    dt = dt.merge(cal, on= \"d\", copy = False)\n",
    "    dt = dt.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt[lag_col] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins :\n",
    "        for lag,lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = dt[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean())\n",
    "    \n",
    "    date_features = {\n",
    "        \n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "#         \"ime\": \"is_month_end\",\n",
    "#         \"ims\": \"is_month_start\",\n",
    "    }\n",
    "    \n",
    "#     dt.drop([\"d\", \"wm_yr_wk\", \"weekday\"], axis=1, inplace = True)\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_DAY = 800 # If you want to load all the data set it to '1' -->  Great  memory overflow  risk !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 s, sys: 3.58 s, total: 41.6 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = create_dt(is_train=True, first_day= FIRST_DAY)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 37s, sys: 11.9 s, total: 3min 49s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "create_fea(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29845446, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['item_id', 'dept_id', 'store_id', 'cat_id', 'state_id'] + [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "useless_cols = [\"id\", \"date\", \"sales\", \"d\", \"wm_yr_wk\", \"weekday\"]\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "X_train = df[train_cols]\n",
    "y_train = df[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label = y_train, categorical_feature=cat_feats, free_raw_data=False)\n",
    "fake_valid_inds = np.random.choice(len(X_train), 1000000)\n",
    "fake_valid_data = lgb.Dataset(X_train.iloc[fake_valid_inds], label = y_train.iloc[fake_valid_inds], categorical_feature=cat_feats,\n",
    "                             free_raw_data=False)   # This is just a subsample of the training set, not a real validation set !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\" : \"poisson\",\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "#         \"nthread\" : 4\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 1500,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/envs/Python-3.6/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 2.6985\n",
      "[100]\tvalid_0's rmse: 2.58533\n",
      "[150]\tvalid_0's rmse: 2.54934\n",
      "[200]\tvalid_0's rmse: 2.51367\n",
      "[250]\tvalid_0's rmse: 2.48897\n",
      "[300]\tvalid_0's rmse: 2.46486\n",
      "[350]\tvalid_0's rmse: 2.44728\n",
      "[400]\tvalid_0's rmse: 2.43307\n",
      "[450]\tvalid_0's rmse: 2.41975\n",
      "[500]\tvalid_0's rmse: 2.40879\n",
      "[550]\tvalid_0's rmse: 2.39863\n",
      "[600]\tvalid_0's rmse: 2.38852\n",
      "[650]\tvalid_0's rmse: 2.38081\n",
      "[700]\tvalid_0's rmse: 2.37381\n",
      "[750]\tvalid_0's rmse: 2.36657\n",
      "[800]\tvalid_0's rmse: 2.36169\n",
      "[850]\tvalid_0's rmse: 2.35508\n",
      "[900]\tvalid_0's rmse: 2.35049\n",
      "[950]\tvalid_0's rmse: 2.34265\n",
      "[1000]\tvalid_0's rmse: 2.33698\n",
      "[1050]\tvalid_0's rmse: 2.33373\n",
      "[1100]\tvalid_0's rmse: 2.32192\n",
      "[1150]\tvalid_0's rmse: 2.30795\n",
      "[1200]\tvalid_0's rmse: 2.30005\n",
      "[1250]\tvalid_0's rmse: 2.29339\n",
      "[1300]\tvalid_0's rmse: 2.28772\n",
      "[1350]\tvalid_0's rmse: 2.27656\n",
      "[1400]\tvalid_0's rmse: 2.27355\n",
      "[1450]\tvalid_0's rmse: 2.26406\n",
      "[1500]\tvalid_0's rmse: 2.25938\n",
      "CPU times: user 6h 54min 44s, sys: 1min 7s, total: 6h 55min 52s\n",
      "Wall time: 26min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m_lgb = lgb.train(params, train_data, valid_sets = [fake_valid_data], verbose_eval=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 1.54 s, total: 29.7 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "te = create_dt(False)\n",
    "te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016-04-25 00:00:00\n",
      "1 2016-04-26 00:00:00\n",
      "2 2016-04-27 00:00:00\n",
      "3 2016-04-28 00:00:00\n",
      "4 2016-04-29 00:00:00\n",
      "5 2016-04-30 00:00:00\n",
      "6 2016-05-01 00:00:00\n",
      "7 2016-05-02 00:00:00\n",
      "8 2016-05-03 00:00:00\n",
      "9 2016-05-04 00:00:00\n",
      "10 2016-05-05 00:00:00\n",
      "11 2016-05-06 00:00:00\n",
      "12 2016-05-07 00:00:00\n",
      "13 2016-05-08 00:00:00\n",
      "14 2016-05-09 00:00:00\n",
      "15 2016-05-10 00:00:00\n",
      "16 2016-05-11 00:00:00\n",
      "17 2016-05-12 00:00:00\n",
      "18 2016-05-13 00:00:00\n",
      "19 2016-05-14 00:00:00\n",
      "20 2016-05-15 00:00:00\n",
      "21 2016-05-16 00:00:00\n",
      "22 2016-05-17 00:00:00\n",
      "23 2016-05-18 00:00:00\n",
      "24 2016-05-19 00:00:00\n",
      "25 2016-05-20 00:00:00\n",
      "26 2016-05-21 00:00:00\n",
      "27 2016-05-22 00:00:00\n",
      "CPU times: user 1h 26min 24s, sys: 2min 47s, total: 1h 29min 11s\n",
      "Wall time: 55min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, 28):\n",
    "    day = fday + timedelta(days=i)\n",
    "    print(i, day)\n",
    "    tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "    create_fea(tst)\n",
    "    tst = tst.loc[tst.date == day , train_cols]\n",
    "    te.loc[te.date == day, \"sales\"] = 1.02*m_lgb.predict(tst) # magic multiplier by kyakovlev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_lib import Project\n",
    "project = Project.access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 251 ms, total: 15.8 s\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]].copy()\n",
    "te_sub.loc[te.date >= fday+ timedelta(days=h), \"id\"] = te_sub.loc[te.date >= fday+timedelta(days=h), \n",
    "                                                                      \"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][[f\"F{i}\" for i in range(1,29)]].reset_index()\n",
    "te_sub.fillna(0., inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60980, 29)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save_data(\"my_kaggle_submission.csv\", te_sub.to_csv(index=False), overwrite=True)\n",
    "te_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
